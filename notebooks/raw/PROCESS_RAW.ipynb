{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>flow</th>\n",
       "      <th>country</th>\n",
       "      <th>tab</th>\n",
       "      <th>enduse</th>\n",
       "      <th>2013.0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SHARE_COUNTRY_EM</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Freight transport</td>\n",
       "      <td>Freight trains</td>\n",
       "      <td>0.90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SHARE_COUNTRY_EM</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Freight transport</td>\n",
       "      <td>Trucks</td>\n",
       "      <td>8.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SHARE_FOSSIL</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Freight transport</td>\n",
       "      <td>Domestic freight ships</td>\n",
       "      <td>88.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SHARE_FOSSIL</td>\n",
       "      <td>Australia</td>\n",
       "      <td>Freight transport</td>\n",
       "      <td>Freight trains</td>\n",
       "      <td>94.43</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               flow    country                tab                  enduse  \\\n",
       "0  SHARE_COUNTRY_EM  Australia  Freight transport          Freight trains   \n",
       "1  SHARE_COUNTRY_EM  Australia  Freight transport                  Trucks   \n",
       "2      SHARE_FOSSIL  Australia  Freight transport  Domestic freight ships   \n",
       "3      SHARE_FOSSIL  Australia  Freight transport          Freight trains   \n",
       "\n",
       "   2013.0  \n",
       "0    0.90  \n",
       "1    8.65  \n",
       "2   88.52  \n",
       "3   94.43  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = {\n",
    "    'CSV': ['', '', '', ''],\n",
    "    'country': ['Australia', 'Australia', 'Australia', 'Australia'],\n",
    "    'tab': ['Freight transport', 'Freight transport', 'Freight transport', 'Freight transport'],\n",
    "    'flow': ['SHARE_COUNTRY_EM', 'SHARE_COUNTRY_EM', 'SHARE_FOSSIL', 'SHARE_FOSSIL'],\n",
    "    'enduse': ['Freight trains', 'Trucks', 'Domestic freight ships', 'Freight trains'],\n",
    "    'activity': ['', '', '', ''],\n",
    "    'unit': ['%', '%', '%', '%'],\n",
    "    'year': [2013.0, 2013.0, 2013.0, 2013.0],\n",
    "    'value': [0.9, 8.65, 88.52, 94.43]\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "pivoted_df = df.pivot_table(index=['flow', 'country',  'tab', 'enduse'], columns='year', values='value', aggfunc='first').reset_index().rename_axis(None, axis=1)\n",
    "\n",
    "pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>A</th>\n",
       "      <th>B</th>\n",
       "      <th>C</th>\n",
       "      <th>D</th>\n",
       "      <th>E</th>\n",
       "      <th>F</th>\n",
       "      <th>G</th>\n",
       "      <th>H</th>\n",
       "      <th>I</th>\n",
       "      <th>J</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     A    B    C    D     E     F     G     H     I     J\n",
       "0  2.0  4.0  7.0  8.0  11.0  13.0  16.0  17.0  19.0  21.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Example DataFrame with 10 columns\n",
    "df = pd.DataFrame({\n",
    "    'A': [np.nan, 2, 3],\n",
    "    'B': [4, np.nan, np.nan],\n",
    "    'C': [np.nan, np.nan, 7],\n",
    "    'D': [8, 9, np.nan],\n",
    "    'E': [np.nan, 11, 12],\n",
    "    'F': [13, np.nan, np.nan],\n",
    "    'G': [np.nan, np.nan, 16],\n",
    "    'H': [17, np.nan, np.nan],\n",
    "    'I': [np.nan, 19, 20],\n",
    "    'J': [21, np.nan, np.nan]\n",
    "})\n",
    "\n",
    "# Function to fill each column with the first non-null value\n",
    "def fill_first_non_null(column):\n",
    "    first_non_null = column.first_valid_index()\n",
    "    return column.fillna(column[first_non_null])\n",
    "\n",
    "# Create the resulting DataFrame\n",
    "result = df.apply(fill_first_non_null).head(1)\n",
    "\n",
    "\n",
    "\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"None of ['Code'] are in the columns\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_864306/815824077.py\u001b[0m in \u001b[0;36m?\u001b[0;34m()\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mpandas\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0mlanguages\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"fr\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/_work/d4g/sdp/shiftdataportal_data/.venv/lib/python3.9/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    327\u001b[0m                     \u001b[0mmsg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marguments\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_format_argument_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mallow_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    328\u001b[0m                     \u001b[0mFutureWarning\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    329\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfind_stack_level\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    330\u001b[0m                 )\n\u001b[0;32m--> 331\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/_work/d4g/sdp/shiftdataportal_data/.venv/lib/python3.9/site-packages/pandas/core/frame.py\u001b[0m in \u001b[0;36m?\u001b[0;34m(self, keys, drop, append, inplace, verify_integrity)\u001b[0m\n\u001b[1;32m   6008\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfound\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6009\u001b[0m                         \u001b[0mmissing\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6010\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6011\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmissing\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 6012\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"None of {missing} are in the columns\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   6013\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6014\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   6015\u001b[0m             \u001b[0mframe\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: \"None of ['Code'] are in the columns\""
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "languages = [\"en\", \"fr\", \"es\"] #, 'zh']  # List of languages\n",
    "\n",
    "# Initialize an empty dataframe\n",
    "df_merged = pd.DataFrame()\n",
    "info_dir = '../../data/_info'  \n",
    "info_file = '__INFO_UN_M49'\n",
    "\n",
    "# Loop through the languages\n",
    "for lang in languages:\n",
    "    # Read the CSV file for the current language\n",
    "    filename = f\"{info_dir}/{info_file}_{lang}.csv\"\n",
    "    df_language = pd.read_csv(filename)\n",
    "    \n",
    "    # Merge the current language dataframe with the merged dataframe\n",
    "    if df_merged.empty:\n",
    "        df_merged = df_language\n",
    "    else:\n",
    "        df_merged = pd.merge(df_merged, df_language, on=\"Code\", how=\"outer\")\n",
    "\n",
    "# Set the language code column as the index\n",
    "df_merged.set_index(\"Code\", inplace=True)\n",
    "\n",
    "# Rename the columns to the respective language names\n",
    "column_names = {\"column_name_en\": \"English\",\n",
    "                \"column_name_fr\": \"French\",\n",
    "                \"column_name_es\": \"Spanish\",\n",
    "                \"column_name_zh\": \"Chinese\"}\n",
    "df_merged.rename(columns=column_names, inplace=True)\n",
    "\n",
    "# Save the resulting dataframe as a CSV file\n",
    "df_merged.to_csv(f\"{info_dir}/{info_file}.csv\")\n",
    "\n",
    "# Display a message upon successful completion\n",
    "print(\"Merged dataframe saved as 'merged_languages.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "RAW SOURCE: EIA\n",
      "CSV NAME: ../../data/_raw/eia/eia_api_ieo_world.csv\n",
      "INFO : False\n",
      "['history', 'region_id', 'region_name', 'scenario', 'scenariodescription', 'seriesid', 'seriesname', 'tableid', 'tablename', 'unit', 'unit_name', 'value', 'year']\n",
      "CSV NAME: ../../data/_raw/eia/eia_api_intl_region.csv\n",
      "INFO : False\n",
      "['activityid', 'activityname', 'dataflagdescription', 'dataflagid', 'productid', 'productname', 'region_id', 'region_name', 'region_type_id', 'region_type_name', 'unit', 'unit_name', 'value', 'year']\n",
      "\n",
      "Expected nb rows for EIA: 644868\n",
      "ACTUAL nb rows for EIA: 644868\n",
      "\n",
      "RAW SOURCE: EMBER\n",
      "CSV NAME: ../../data/_raw/ember/ember_file_elec_review_europe_year.csv\n",
      "INFO : False\n",
      "['area', 'area_type', 'category', 'country_iso3', 'subcategory', 'unit', 'unit_name', 'value', 'variable', 'year', 'yoy_%_change', 'yoy_absolute_change']\n",
      "CSV NAME: ../../data/_raw/ember/ember_file_elec_review_global_month.csv\n",
      "INFO : False\n",
      "['area', 'area_type', 'category', 'country_iso3', 'ember_region', 'month', 'subcategory', 'unit', 'unit_name', 'value', 'variable', 'year', 'yoy_%_change', 'yoy_absolute_change']\n",
      "CSV NAME: ../../data/_raw/ember/ember_file_elec_all_month.csv\n",
      "INFO : False\n",
      "['area', 'area_type', 'category', 'continent', 'country_iso3', 'ember_region', 'eu', 'g20', 'g7', 'month', 'oecd', 'subcategory', 'unit', 'unit_name', 'value', 'variable', 'year', 'yoy_%_change', 'yoy_absolute_change']\n",
      "CSV NAME: ../../data/_raw/ember/ember_file_elec_review_europe_month.csv\n",
      "INFO : False\n",
      "['area', 'area_type', 'category', 'country_iso3', 'month', 'subcategory', 'unit', 'unit_name', 'value', 'variable', 'year', 'yoy_%_change', 'yoy_absolute_change']\n",
      "CSV NAME: ../../data/_raw/ember/ember_file_elec_review_global_year.csv\n",
      "INFO : False\n",
      "['area', 'area_type', 'category', 'country_iso3', 'ember_region', 'subcategory', 'unit', 'unit_name', 'value', 'variable', 'year', 'yoy_%_change', 'yoy_absolute_change']\n",
      "CSV NAME: ../../data/_raw/ember/ember_file_elec_all_year.csv\n",
      "INFO : False\n",
      "['area', 'area_type', 'category', 'continent', 'country_iso3', 'ember_region', 'eu', 'g20', 'g7', 'oecd', 'subcategory', 'unit', 'unit_name', 'value', 'variable', 'year', 'yoy_%_change', 'yoy_absolute_change']\n",
      "\n",
      "Expected nb rows for EMBER: 960287\n",
      "ACTUAL nb rows for EMBER: 960287\n",
      "\n",
      "RAW SOURCE: WB\n",
      "CSV NAME: ../../data/_raw/wb/__info_wb_api_topics.csv\n",
      "INFO : True\n",
      "['id', 'source_note', 'value']\n",
      "CSV NAME: ../../data/_raw/wb/__info_wb_api_countries_fr.csv\n",
      "INFO : True\n",
      "['adminregion_id', 'adminregion_iso2', 'adminregion_value', 'capitalcity', 'id', 'incomelevel_id', 'incomelevel_iso2', 'incomelevel_value', 'iso2', 'latitude', 'lendingtype_id', 'lendingtype_iso2', 'lendingtype_value', 'longitude', 'name', 'region_id', 'region_iso2', 'region_value']\n",
      "CSV NAME: ../../data/_raw/wb/wb_api_all_gas_em_sect.csv\n",
      "INFO : False\n",
      "['country_iso3', 'decimal', 'indicator_id', 'indicator_value', 'value', 'year']\n",
      "CSV NAME: ../../data/_raw/wb/wb_api_all_co2.csv\n",
      "INFO : False\n",
      "['country_iso3', 'decimal', 'indicator_id', 'indicator_value', 'value', 'year']\n",
      "CSV NAME: ../../data/_raw/wb/__info_wb_api_indicators_fr.csv\n",
      "INFO : True\n",
      "['id', 'name', 'source_id', 'source_note', 'source_organization', 'source_value', 'topics']\n",
      "CSV NAME: ../../data/_raw/wb/__info_wb_api_regions_fr.csv\n",
      "INFO : True\n",
      "['id', 'iso2', 'name', 'uid']\n",
      "CSV NAME: ../../data/_raw/wb/__info_wb_api_sources_fr.csv\n",
      "INFO : True\n",
      "['concepts', 'data_availability', 'id', 'last_updated', 'metadata_availability', 'name', 'uid']\n",
      "CSV NAME: ../../data/_raw/wb/__info_wb_api_regions.csv\n",
      "INFO : True\n",
      "['id', 'iso2', 'name', 'uid']\n",
      "CSV NAME: ../../data/_raw/wb/wb_api_all_ghge_sect.csv\n",
      "INFO : False\n",
      "['country_iso3', 'decimal', 'indicator_id', 'indicator_value', 'value', 'year']\n",
      "CSV NAME: ../../data/_raw/wb/wb_api_all_pop.csv\n",
      "INFO : False\n",
      "['country_iso3', 'indicator_id', 'indicator_value', 'value', 'year']\n",
      "CSV NAME: ../../data/_raw/wb/__info_wb_api_indicators.csv\n",
      "INFO : True\n",
      "['id', 'name', 'source_id', 'source_note', 'source_organization', 'source_value', 'topics']\n",
      "CSV NAME: ../../data/_raw/wb/__info_wb_api_sources.csv\n",
      "INFO : True\n",
      "['concepts', 'data_availability', 'id', 'last_updated', 'metadata_availability', 'name', 'uid']\n",
      "CSV NAME: ../../data/_raw/wb/__info_wb_api_countries.csv\n",
      "INFO : True\n",
      "['adminregion_id', 'adminregion_iso2', 'adminregion_value', 'capitalcity', 'id', 'incomelevel_id', 'incomelevel_iso2', 'incomelevel_value', 'iso2', 'latitude', 'lendingtype_id', 'lendingtype_iso2', 'lendingtype_value', 'longitude', 'name', 'region_id', 'region_iso2', 'region_value']\n",
      "CSV NAME: ../../data/_raw/wb/wb_api_all_gdp.csv\n",
      "INFO : False\n",
      "['country_iso3', 'indicator_id', 'indicator_value', 'value', 'year']\n",
      "CSV NAME: ../../data/_raw/wb/__info_wb_api_topics_fr.csv\n",
      "INFO : True\n",
      "['id', 'source_note', 'value']\n",
      "\n",
      "Expected nb rows for WB: 453132\n",
      "ACTUAL nb rows for WB: 453132\n",
      "\n",
      "RAW SOURCE: BP\n",
      "CSV NAME: ../../data/_raw/bp/bp_file_energy_review_world.csv\n",
      "INFO : False\n",
      "['cis', 'country', 'eu', 'iso3166_alpha3', 'iso3166_numeric', 'oecd', 'opec', 'region', 'subregion', 'value', 'variable', 'year']\n",
      "\n",
      "Expected nb rows for BP: 238516\n",
      "ACTUAL nb rows for BP: 238516\n",
      "\n",
      "RAW SOURCE: IEA\n",
      "CSV NAME: ../../data/_raw/iea/iea_api_eei.csv\n",
      "INFO : False\n",
      "['activity', 'country', 'enduse', 'flow', 'tab', 'unit', 'unit_name', 'value', 'year']\n",
      "\n",
      "Expected nb rows for IEA: 126470\n",
      "ACTUAL nb rows for IEA: 126470\n",
      "\n",
      "Expected nb rows for ALL: 8530934\n",
      "ACTUAL ALL DF nb rows: 5\n",
      "INFO NB COLS 29\n",
      "INFO COLS ['adminregion_id', 'adminregion_iso2', 'adminregion_value', 'capitalcity', 'concepts', 'data_availability', 'id', 'incomelevel_id', 'incomelevel_iso2', 'incomelevel_value', 'iso2', 'last_updated', 'latitude', 'lendingtype_id', 'lendingtype_iso2', 'lendingtype_value', 'longitude', 'metadata_availability', 'name', 'region_id', 'region_iso2', 'region_value', 'source_id', 'source_note', 'source_organization', 'source_value', 'topics', 'uid', 'value']\n",
      "DATA NB COLS 50\n",
      "DATA COLS ['activity', 'activityid', 'activityname', 'area', 'area_type', 'category', 'cis', 'continent', 'country', 'country_iso3', 'dataflagdescription', 'dataflagid', 'decimal', 'ember_region', 'enduse', 'eu', 'flow', 'g20', 'g7', 'history', 'indicator_id', 'indicator_value', 'iso3166_alpha3', 'iso3166_numeric', 'month', 'oecd', 'opec', 'productid', 'productname', 'region', 'region_id', 'region_name', 'region_type_id', 'region_type_name', 'scenario', 'scenariodescription', 'seriesid', 'seriesname', 'subcategory', 'subregion', 'tab', 'tableid', 'tablename', 'unit', 'unit_name', 'value', 'variable', 'year', 'yoy_%_change', 'yoy_absolute_change']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import io\n",
    "import re\n",
    "import numpy as np\n",
    "\n",
    "exclude_columns = [\n",
    "    'iso3166_numeric'\n",
    "    \n",
    "]\n",
    "\n",
    "# Function to fill each column with the first non-null value\n",
    "def first_non_null(column):\n",
    "    first_non_null = column.first_valid_index()\n",
    "    return column.fillna(column[first_non_null])\n",
    "\n",
    "# Function to replace a substring in a string column\n",
    "def process_values(value):   \n",
    "    if isinstance(value, str):\n",
    "        value = re.sub(r'[\\r\\n]+', ' - ', value).strip('\"\\' \\)\\()')\n",
    "    \n",
    "    return np.nan if not value else value\n",
    "\n",
    "\n",
    "def exclude(column_name):\n",
    "    if column_name in exclude_columns:\n",
    "        return True\n",
    "    if str(column_name).startswith('dataflag'):\n",
    "        return True\n",
    "\n",
    "def process_columns(column_name):\n",
    "    #return column_name\n",
    "    \n",
    "    # BASIC \n",
    "    column_name = re.sub(r'([A-Z]+)', r' \\1', column_name.lower())\n",
    "    column_name = re.sub(r'(\\s+|\\.)', r' ', column_name).strip()\n",
    "    column_name = re.sub(r'(\\s+)', r'_', column_name)   \n",
    "    \n",
    "    # COUNTRY AND REGION \n",
    "    column_name = re.sub(r'(iso[2-3])code', r'\\1', column_name)\n",
    "    column_name = re.sub(r'(country)(iso[2-3])', r'\\1_\\2', column_name)\n",
    "    column_name = re.sub(r'(country)(region)', r'\\2', column_name)\n",
    "    column_name = re.sub(r'(?<=region)(?=type|name)', '_', column_name)\n",
    "    column_name = re.sub(r'(?<=region)(?=id)', '_', column_name)\n",
    "    column_name = re.sub(r'(?<=type)(?=id|name)', '_', column_name)\n",
    "\n",
    "    \n",
    "    # WB specific\n",
    "    column_name = re.sub(r'(?<=source)(?=organization|note)', '_', column_name)\n",
    "    column_name = re.sub(r'(?<=data)(?=availability)', '_', column_name)\n",
    "    \n",
    "    # EIA specific\n",
    "    if (column_name=='period'):\n",
    "        column_name = column_name.replace('period','year')   \n",
    "            \n",
    "    # UNIT\n",
    "    column_name = re.sub(r'(?<=unit)(?=name)', '_', column_name)\n",
    "    \n",
    "    # MISC\n",
    "    if (column_name=='var'):\n",
    "        column_name = column_name.replace('var','variable')\n",
    "            \n",
    "    # UID\n",
    "    if (column_name=='code'):\n",
    "        column_name = re.sub(r'code', 'uid', column_name) \n",
    "    #column_name = column_name.replace('country_id','country_iso2')  \n",
    "    column_name = column_name.replace('country_code','country_iso3')  \n",
    " \n",
    "    # DATE RELATED    \n",
    "    column_name = re.sub(r'(?<=last)(?=updated)', '_', column_name) \n",
    "    \n",
    "    return column_name\n",
    "\n",
    "# FORMAT DF: \n",
    "def process_df(df):\n",
    "    # PROCESSING \n",
    "    # STRING VALUES (might set to NaN)\n",
    "    df = df.applymap(process_values) \n",
    "    # Uniformize NaN values\n",
    "    df = df.replace(['', 'nan'], np.nan)  \n",
    "                \n",
    "    # Drop all columns having only NaN\n",
    "    df = df.dropna(axis=1, how='all')  \n",
    "\n",
    "    # Replace column names using the format function\n",
    "    df = df.rename(columns=process_columns)\n",
    "\n",
    "    # Filter value if exists\n",
    "    if ('value' in df.columns):\n",
    "        df = df.dropna(subset=['value'])\n",
    "\n",
    "    # DATE: Split the 'date' using regex if it matches the pattern\n",
    "    # Date column format: YYYY-MM-DD OR YYYY\n",
    "    if ('date' in df.columns):\n",
    "        df[['year', 'month']] = df['date'].astype(str).str.extract(r'^(\\d{4})-(\\d{2})-\\d{2}$').fillna(np.nan)\n",
    "        # Drop all columns having only NaN AGAIN due to previously added columns\n",
    "        df = df.dropna(axis=1, how='all') \n",
    "        \n",
    "        if ('year' in df.columns):\n",
    "            df = df.drop(columns=['date'])\n",
    "        else:\n",
    "            # Date is in YYYY format\n",
    "            df = df.rename(columns={'date': 'year'})   \n",
    "    \n",
    "    if ('year' in df.columns):\n",
    "            df['year']=df['year'].astype(int)\n",
    "            if ('month' in df.columns):\n",
    "                df['month']=df['month'].astype(int)    \n",
    "    \n",
    "    # Unit\n",
    "    if ('unit' in df.columns and not 'unit_name' in df.columns ):\n",
    "        df['unit_name']=df['unit']  \n",
    "    \n",
    "    # WB SPECIFIC    \n",
    "    # Manage inconsistent country/region iso2 or iso3 in indicators\n",
    "    if ('country_id' in df.columns and 'country_value' in df.columns ):\n",
    "        if ('country_iso3' in df.columns):\n",
    "            df['country_iso3'] = df['country_iso3'].fillna(df['country_id'])\n",
    "        else:\n",
    "            df['country_iso3']=df['country_id']\n",
    "        df = df.drop(columns=['country_id','country_value'])\n",
    "            \n",
    "    return df\n",
    "\n",
    "\n",
    "# Create an empty set to store unique column names\n",
    "data_columns = set()\n",
    "info_columns = set()\n",
    "all_df = pd.DataFrame()\n",
    "all_rows=0\n",
    "\n",
    "# \n",
    "info_dir = '../../data/_raw'  \n",
    "for root, dirs, _ in os.walk(info_dir):\n",
    "    for dir in dirs:\n",
    "        # Iterate over files within each subdirectory\n",
    "        source_dir = os.path.join(root, dir)\n",
    "        \n",
    "        print(f'\\nRAW SOURCE: {dir.upper()}') \n",
    "                       \n",
    "        info_df = pd.DataFrame()\n",
    "        data_df = pd.DataFrame()\n",
    "        # to check\n",
    "        nb_rows=0\n",
    "\n",
    "        has_info = False\n",
    "        for file in os.listdir(source_dir):\n",
    "\n",
    "            info  =False\n",
    "            # Perform operations on each file          \n",
    "            if file.endswith(\".csv\"):\n",
    "\n",
    "                # Read only the first line of the CSV file\n",
    "                csv_path =  os.path.join(source_dir, file)\n",
    "                csv_name = os.path.splitext(os.path.basename(csv_path))[0]\n",
    "               \n",
    "                print(f'CSV NAME: {csv_path}')\n",
    "                info = file.startswith(\"__info\")\n",
    "                print(f'INFO : {info}')\n",
    "                                \n",
    "                # Build df\n",
    "                df = pd.read_csv(csv_path, low_memory=False) \n",
    "                \n",
    "                ## PROCESSING\n",
    "                df = process_df(df)\n",
    "                \n",
    "                nb_rows += 0 if info else len(df)\n",
    "                all_rows += nb_rows\n",
    "\n",
    "                print(sorted(list(df.columns)))                                \n",
    "\n",
    "                #output_df = info_df if info else data_df\n",
    "                # Append the current iteration DataFrame to the output DataFrame\n",
    "                if (info) :\n",
    "                    info_columns.update(df.columns)\n",
    "                    info_df = pd.concat([info_df, df], ignore_index=True)\n",
    "                else:\n",
    "                    data_columns.update(df.columns)\n",
    "                    data_df = pd.concat([data_df, df], ignore_index=True)\n",
    "                        \n",
    "        print(f'\\nExpected nb rows for {dir.upper()}: {nb_rows}')\n",
    "        print(f'ACTUAL nb rows for {dir.upper()}: {len(data_df)}')\n",
    "        \n",
    "        if (not info_df.empty):\n",
    "            info_df = info_df.drop_duplicates()\n",
    "            info_df['RAW']=dir.upper()\n",
    "            info_df.to_csv(f'_INFO_{dir.upper()}.csv', index=False)\n",
    "                        \n",
    "        if (not data_df.empty):\n",
    "            data_df = data_df.drop_duplicates()\n",
    "            data_df['RAW']=dir.upper()\n",
    "            data_df.to_csv(f'PROCESSED_{dir.upper()}.csv', index=False)\n",
    "\n",
    "            \n",
    "            # ONLY FOR TEST\n",
    "            # Create the resulting DataFrame\n",
    "            result = data_df.apply(fill_first_non_null).head(1)\n",
    "            #selected_columns = list(set(output_df.columns).intersection(column_names))\n",
    "            # # Step 3: Create the output DataFrame with all columns from the exhaustive list\n",
    "            #all_pdf = pd.DataFrame(columns=[\"CSV\"] + column_names)\n",
    "            #all_df[selected_columns] = output_df[selected_columns].head(100)\n",
    "            \n",
    "            all_df = pd.concat([all_df,  result], ignore_index=True)\n",
    "\n",
    "print(f'\\nExpected nb rows for ALL: {all_rows}')\n",
    "print(f'ACTUAL ALL DF nb rows: {len(all_df)}')\n",
    "all_df.to_csv(f'PROCESSED__ALL.csv', index=False)        \n",
    "# Convert the set to a list and sort it\n",
    "info_columns = sorted(list(info_columns))\n",
    "print(f'INFO NB COLS {len(info_columns)}')\n",
    "print(f'INFO COLS {info_columns}')\n",
    "\n",
    "data_columns = sorted(list(data_columns))\n",
    "print(f'DATA NB COLS {len(data_columns)}')\n",
    "print(f'DATA COLS {data_columns}')\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RAW</th>\n",
       "      <th>activity</th>\n",
       "      <th>activityid</th>\n",
       "      <th>activityname</th>\n",
       "      <th>adminregion_id</th>\n",
       "      <th>adminregion_iso2</th>\n",
       "      <th>adminregion_value</th>\n",
       "      <th>area</th>\n",
       "      <th>area_type</th>\n",
       "      <th>capitalcity</th>\n",
       "      <th>...</th>\n",
       "      <th>tablename</th>\n",
       "      <th>topics</th>\n",
       "      <th>uid</th>\n",
       "      <th>unit</th>\n",
       "      <th>unit_name</th>\n",
       "      <th>value</th>\n",
       "      <th>variable</th>\n",
       "      <th>year</th>\n",
       "      <th>yoy_%_change</th>\n",
       "      <th>yoy_absolute_change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EIA</td>\n",
       "      <td>Population</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Production</td>\n",
       "      <td>SAS</td>\n",
       "      <td>8S</td>\n",
       "      <td>Asie du Sud</td>\n",
       "      <td>Austria</td>\n",
       "      <td>Country</td>\n",
       "      <td>Oranjestad</td>\n",
       "      <td>...</td>\n",
       "      <td>Gross output by region and sector</td>\n",
       "      <td>[{'id': '11', 'value': 'Pauvreté'}]</td>\n",
       "      <td>AFE</td>\n",
       "      <td>billion 2015 dollars</td>\n",
       "      <td>billion 2015 dollars</td>\n",
       "      <td>7972.0825</td>\n",
       "      <td>Demand</td>\n",
       "      <td>2050.0</td>\n",
       "      <td>2.57</td>\n",
       "      <td>1.09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 78 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   RAW    activity  activityid activityname adminregion_id adminregion_iso2  \\\n",
       "0  EIA  Population         1.0   Production            SAS               8S   \n",
       "\n",
       "  adminregion_value     area area_type capitalcity  ...  \\\n",
       "0       Asie du Sud  Austria   Country  Oranjestad  ...   \n",
       "\n",
       "                           tablename                               topics  \\\n",
       "0  Gross output by region and sector  [{'id': '11', 'value': 'Pauvreté'}]   \n",
       "\n",
       "   uid                  unit             unit_name      value variable  \\\n",
       "0  AFE  billion 2015 dollars  billion 2015 dollars  7972.0825   Demand   \n",
       "\n",
       "     year  yoy_%_change  yoy_absolute_change  \n",
       "0  2050.0          2.57                 1.09  \n",
       "\n",
       "[1 rows x 78 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df = all_df.sort_index(axis=1)\n",
    "# Select the first non-null value from each column\n",
    "sample_row = all_df.apply(fill_first_non_null).head(1)\n",
    "\n",
    "\n",
    "sample_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Area', 'Country code', 'Date', 'Area type', 'Ember region', 'Category', 'Subcategory', 'Variable', 'Unit', 'Value', 'YoY absolute change', 'YoY % change']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Area</th>\n",
       "      <th>Country code</th>\n",
       "      <th>Date</th>\n",
       "      <th>Area type</th>\n",
       "      <th>Ember region</th>\n",
       "      <th>Category</th>\n",
       "      <th>Subcategory</th>\n",
       "      <th>Variable</th>\n",
       "      <th>Unit</th>\n",
       "      <th>Value</th>\n",
       "      <th>YoY absolute change</th>\n",
       "      <th>YoY % change</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>ARG</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Country</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "      <td>Electricity demand</td>\n",
       "      <td>Demand</td>\n",
       "      <td>Demand</td>\n",
       "      <td>TWh</td>\n",
       "      <td>12.77</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>ARG</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Country</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "      <td>Electricity generation</td>\n",
       "      <td>Aggregate fuel</td>\n",
       "      <td>Clean</td>\n",
       "      <td>%</td>\n",
       "      <td>34.56</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>ARG</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Country</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "      <td>Electricity generation</td>\n",
       "      <td>Aggregate fuel</td>\n",
       "      <td>Fossil</td>\n",
       "      <td>%</td>\n",
       "      <td>65.44</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>ARG</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Country</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "      <td>Electricity generation</td>\n",
       "      <td>Aggregate fuel</td>\n",
       "      <td>Hydro, bioenergy and other renewables</td>\n",
       "      <td>%</td>\n",
       "      <td>29.08</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Argentina</td>\n",
       "      <td>ARG</td>\n",
       "      <td>2018-01-01</td>\n",
       "      <td>Country</td>\n",
       "      <td>Latin America and Caribbean</td>\n",
       "      <td>Electricity generation</td>\n",
       "      <td>Aggregate fuel</td>\n",
       "      <td>Renewables</td>\n",
       "      <td>%</td>\n",
       "      <td>29.55</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312568</th>\n",
       "      <td>World</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Power sector emissions</td>\n",
       "      <td>Fuel</td>\n",
       "      <td>Other Fossil</td>\n",
       "      <td>MtCO2</td>\n",
       "      <td>49.28</td>\n",
       "      <td>4.59</td>\n",
       "      <td>10.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312569</th>\n",
       "      <td>World</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Power sector emissions</td>\n",
       "      <td>Fuel</td>\n",
       "      <td>Other Renewables</td>\n",
       "      <td>MtCO2</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.01</td>\n",
       "      <td>2.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312570</th>\n",
       "      <td>World</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Power sector emissions</td>\n",
       "      <td>Fuel</td>\n",
       "      <td>Solar</td>\n",
       "      <td>MtCO2</td>\n",
       "      <td>3.76</td>\n",
       "      <td>0.52</td>\n",
       "      <td>16.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312571</th>\n",
       "      <td>World</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Power sector emissions</td>\n",
       "      <td>Fuel</td>\n",
       "      <td>Wind</td>\n",
       "      <td>MtCO2</td>\n",
       "      <td>2.32</td>\n",
       "      <td>0.22</td>\n",
       "      <td>10.48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312572</th>\n",
       "      <td>World</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2022-12-01</td>\n",
       "      <td>Region</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Power sector emissions</td>\n",
       "      <td>Total</td>\n",
       "      <td>Total emissions</td>\n",
       "      <td>MtCO2</td>\n",
       "      <td>1091.81</td>\n",
       "      <td>30.91</td>\n",
       "      <td>2.91</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>312573 rows × 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Area Country code        Date Area type  \\\n",
       "0       Argentina          ARG  2018-01-01   Country   \n",
       "1       Argentina          ARG  2018-01-01   Country   \n",
       "2       Argentina          ARG  2018-01-01   Country   \n",
       "3       Argentina          ARG  2018-01-01   Country   \n",
       "4       Argentina          ARG  2018-01-01   Country   \n",
       "...           ...          ...         ...       ...   \n",
       "312568      World          NaN  2022-12-01    Region   \n",
       "312569      World          NaN  2022-12-01    Region   \n",
       "312570      World          NaN  2022-12-01    Region   \n",
       "312571      World          NaN  2022-12-01    Region   \n",
       "312572      World          NaN  2022-12-01    Region   \n",
       "\n",
       "                       Ember region                Category     Subcategory  \\\n",
       "0       Latin America and Caribbean      Electricity demand          Demand   \n",
       "1       Latin America and Caribbean  Electricity generation  Aggregate fuel   \n",
       "2       Latin America and Caribbean  Electricity generation  Aggregate fuel   \n",
       "3       Latin America and Caribbean  Electricity generation  Aggregate fuel   \n",
       "4       Latin America and Caribbean  Electricity generation  Aggregate fuel   \n",
       "...                             ...                     ...             ...   \n",
       "312568                          NaN  Power sector emissions            Fuel   \n",
       "312569                          NaN  Power sector emissions            Fuel   \n",
       "312570                          NaN  Power sector emissions            Fuel   \n",
       "312571                          NaN  Power sector emissions            Fuel   \n",
       "312572                          NaN  Power sector emissions           Total   \n",
       "\n",
       "                                     Variable   Unit    Value  \\\n",
       "0                                      Demand    TWh    12.77   \n",
       "1                                       Clean      %    34.56   \n",
       "2                                      Fossil      %    65.44   \n",
       "3       Hydro, bioenergy and other renewables      %    29.08   \n",
       "4                                  Renewables      %    29.55   \n",
       "...                                       ...    ...      ...   \n",
       "312568                           Other Fossil  MtCO2    49.28   \n",
       "312569                       Other Renewables  MtCO2     0.38   \n",
       "312570                                  Solar  MtCO2     3.76   \n",
       "312571                                   Wind  MtCO2     2.32   \n",
       "312572                        Total emissions  MtCO2  1091.81   \n",
       "\n",
       "        YoY absolute change  YoY % change  \n",
       "0                       NaN           NaN  \n",
       "1                       NaN           NaN  \n",
       "2                       NaN           NaN  \n",
       "3                       NaN           NaN  \n",
       "4                       NaN           NaN  \n",
       "...                     ...           ...  \n",
       "312568                 4.59         10.27  \n",
       "312569                 0.01          2.70  \n",
       "312570                 0.52         16.05  \n",
       "312571                 0.22         10.48  \n",
       "312572                30.91          2.91  \n",
       "\n",
       "[312573 rows x 12 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "\n",
    "csv_file_path = \"../../data/_raw/ember/ember_file_elec_review_global_month.csv\"\n",
    "csv_file_name = os.path.splitext(os.path.basename(csv_file_path))[0]  # Extract CSV file name\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Uniformize NaN\n",
    "df = df.replace(['', 'nan'], np.nan)\n",
    "# Drop all columns having only NaN\n",
    "df = df.dropna(axis=1, how='all')  \n",
    "\n",
    "# Replace column names using the format function\n",
    "df = df.rename(columns=process_columns)\n",
    "\n",
    "# Filter value if exists\n",
    "if ('value' in df.columns):\n",
    "    df = df.dropna(subset=['value'])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# DATE: Split the 'date' using regex if it matches the pattern\n",
    "# Date column format: YYYY-MM-DD OR YYYY\n",
    "if ('date' in df.columns):\n",
    "    df[['year', 'month']] = df['date'].astype(str).str.extract(r'^(\\d{4})-(\\d{2})-\\d{2}$').fillna(np.nan)    \n",
    "\n",
    "# Drop all columns having only NaN AGAIN due to previously added columns\n",
    "df = df.dropna(axis=1, how='all') \n",
    "if ('year' in df.columns):\n",
    "    df = df.drop('date', axis=1)\n",
    "else:\n",
    "    # Date is in YYYY format\n",
    "    df = df.rename(columns={'date': 'year'})\n",
    " \n",
    "\n",
    "print(list(df.columns))\n",
    "df\n",
    "# selected_columns = list(set(df_csv.columns).intersection(column_names))\n",
    "\n",
    "# # Step 3: Create the output DataFrame with all columns from the exhaustive list\n",
    "# output_df = pd.DataFrame(columns=[\"CSV\"] + column_names)\n",
    "\n",
    "# # Step 4: Fill the matching columns from the CSV file in the output DataFrame\n",
    "# output_df[selected_columns] = df_csv[selected_columns]\n",
    "\n",
    "\n",
    "# output_df[\"CSV\"] = csv_file_name\n",
    "# output_df = output_df.dropna(axis=1, how='all')\n",
    "# print(len(list(output_df.columns)))\n",
    "\n",
    "# output_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install rapidfuzz\n",
    "# %pip install fuzzywuzzy\n",
    "\n",
    "# import pandas as pd\n",
    "# from rapidfuzz import fuzz as rfuzz\n",
    "# from rapidfuzz import process as rprocess\n",
    "# from fuzzywuzzy import fuzz as ffuzz\n",
    "# from fuzzywuzzy import process as fprocess\n",
    "# import re\n",
    "\n",
    "# df=output_df\n",
    "# # Perform fuzzy matching on the column names list using rapidfuzz\n",
    "# target_column = \"region\"\n",
    "# threshold = 0  # Adjust the threshold as per your requirements\n",
    "\n",
    "# matches_rfuzz = rprocess.extract(target_column, df['fuzzy'])\n",
    "# matched_columns_rfuzz = [match[0] for match in matches_rfuzz if match[1] >= threshold]\n",
    "# matched_columns_rfuzz = sorted(list(set(matched_columns_rfuzz)))\n",
    "\n",
    "# filtered_values_rfuzz = output_df.loc[df[\"fuzzy\"].isin(matched_columns_rfuzz), \"column\"].tolist()\n",
    "\n",
    "# #print(\"RapidFuzz Matches:\")\n",
    "# #print(matched_columns_rfuzz)\n",
    "\n",
    "# # Perform fuzzy matching on the column names list using fuzzywuzzy\n",
    "# matches_ffuzz = fprocess.extract(target_column, df['fuzzy'])\n",
    "# matched_columns_ffuzz = [match[0] for match in matches_ffuzz if match[1] >= threshold]\n",
    "# matched_columns_ffuzz = sorted(list(set(matched_columns_ffuzz)))\n",
    "\n",
    "# filtered_values_ffuzz = df.loc[df[\"fuzzy\"].isin(matched_columns_ffuzz), \"column\"].tolist()\n",
    "\n",
    "# #print(\"\\nFuzzyWuzzy Matches:\")\n",
    "# #print(matched_columns_ffuzz)\n",
    "\n",
    "# # Combine the matches from both libraries and remove duplicates\n",
    "# all_matches = sorted(list(set(filtered_values_rfuzz + filtered_values_ffuzz)))\n",
    "\n",
    "# print(\"\\nMatches\")\n",
    "# print(all_matches)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
